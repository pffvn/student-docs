<!DOCTYPE html>
<html class="google" lang="en">
  <head>
    <meta charset="utf-8">
    <script>
    (function(H){H.className=H.className.replace(/\bgoogle\b/,'google-js')})(document.documentElement)
    </script>
    <meta content="initial-scale=1, minimum-scale=1, width=device-width" name="viewport">
    <title>
      Google - Site Reliability Engineering
    </title>
    <script src="../js/google.js">
    </script>
    <script>
    new gweb.analytics.AutoTrack({profile:"UA-75468017-1"});
    </script>
    <link href="../css/opensans.css" rel=
    "stylesheet">
    <link href="../css/main.min.css" rel="stylesheet">
    <link href=
    '../css/roboto.css'
    rel='stylesheet' type='text/css'>
    <link href="../../images/favicon.ico" rel="shortcut icon">
  </head>
  <body>
    <div class="menu-closed" id="curtain"></div>
    <div class="header clearfix">
      <div class="header-wrraper">
        <a class="expand" id="burger-menu"></a>
        <h2 class="chapter-title">
          Chapter 31 - Communication and Collaboration in SRE
        </h2>
      </div>
    </div>
    <div class="expands" id="overlay-element">
      <div class="logo">
        <a href="https://www.google.com"><img alt="Google" src=
        "../../images/googlelogo-grey-color.png"></a>
      </div>
      <ol class="dropdown-content hide" id="drop-down">
        <li>
          <a class="menu-buttons" href="../index.html">Table of Contents</a>
        </li>
        <li>
          <a class="menu-buttons" href="foreword.html">Foreword</a>
        </li>
        <li>
          <a class="menu-buttons" href="preface.html">Preface</a>
        </li>
        <li>
          <a class="menu-buttons" href="part1.html">Part I - Introduction</a>
        </li>
        <li>
          <a class="menu-buttons" href="introduction.html">1. Introduction</a>
        </li>
        <li>
          <a class="menu-buttons" href="production-environment.html">2. The
          Production Environment at Google, from the Viewpoint of an SRE</a>
        </li>
        <li>
          <a class="menu-buttons" href="part2.html">Part II - Principles</a>
        </li>
        <li>
          <a class="menu-buttons" href="embracing-risk.html">3. Embracing
          Risk</a>
        </li>
        <li>
          <a class="menu-buttons" href="service-level-objectives.html">4.
          Service Level Objectives</a>
        </li>
        <li>
          <a class="menu-buttons" href="eliminating-toil.html">5. Eliminating
          Toil</a>
        </li>
        <li>
          <a class="menu-buttons" href="monitoring-distributed-systems.html">6.
          Monitoring Distributed Systems</a>
        </li>
        <li>
          <a class="menu-buttons" href="automation-at-google.html">7. The
          Evolution of Automation at Google</a>
        </li>
        <li>
          <a class="menu-buttons" href="release-engineering.html">8. Release
          Engineering</a>
        </li>
        <li>
          <a class="menu-buttons" href="simplicity.html">9. Simplicity</a>
        </li>
        <li>
          <a class="menu-buttons" href="part3.html">Part III - Practices</a>
        </li>
        <li>
          <a class="menu-buttons" href="practical-alerting.html">10. Practical
          Alerting</a>
        </li>
        <li>
          <a class="menu-buttons" href="being-on-call.html">11. Being
          On-Call</a>
        </li>
        <li>
          <a class="menu-buttons" href="effective-troubleshooting.html">12.
          Effective Troubleshooting</a>
        </li>
        <li>
          <a class="menu-buttons" href="emergency-response.html">13. Emergency
          Response</a>
        </li>
        <li>
          <a class="menu-buttons" href="managing-incidents.html">14. Managing
          Incidents</a>
        </li>
        <li>
          <a class="menu-buttons" href="postmortem-culture.html">15. Postmortem
          Culture: Learning from Failure</a>
        </li>
        <li>
          <a class="menu-buttons" href="tracking-outages.html">16. Tracking
          Outages</a>
        </li>
        <li>
          <a class="menu-buttons" href="testing-reliability.html">17. Testing
          for Reliability</a>
        </li>
        <li>
          <a class="menu-buttons" href="software-engineering-in-sre.html">18.
          Software Engineering in SRE</a>
        </li>
        <li>
          <a class="menu-buttons" href="load-balancing-frontend.html">19. Load
          Balancing at the Frontend</a>
        </li>
        <li>
          <a class="menu-buttons" href="load-balancing-datacenter.html">20. Load
          Balancing in the Datacenter</a>
        </li>
        <li>
          <a class="menu-buttons" href="handling-overload.html">21. Handling
          Overload</a>
        </li>
        <li>
          <a class="menu-buttons" href="addressing-cascading-failures.html">22.
          Addressing Cascading Failures</a>
        </li>
        <li>
          <a class="menu-buttons" href="managing-critical-state.html">23.
          Managing Critical State: Distributed Consensus for Reliability</a>
        </li>
        <li>
          <a class="menu-buttons" href=
          "distributed-periodic-scheduling.html">24. Distributed Periodic
          Scheduling with Cron</a>
        </li>
        <li>
          <a class="menu-buttons" href="data-processing-pipelines.html">25. Data
          Processing Pipelines</a>
        </li>
        <li>
          <a class="menu-buttons" href="data-integrity.html">26. Data Integrity:
          What You Read Is What You Wrote</a>
        </li>
        <li>
          <a class="menu-buttons" href="reliable-product-launches.html">27.
          Reliable Product Launches at Scale</a>
        </li>
        <li>
          <a class="menu-buttons" href="part4.html">Part IV - Management</a>
        </li>
        <li>
          <a class="menu-buttons" href="accelerating-sre-on-call.html">28.
          Accelerating SREs to On-Call and Beyond</a>
        </li>
        <li>
          <a class="menu-buttons" href="dealing-with-interrupts.html">29.
          Dealing with Interrupts</a>
        </li>
        <li>
          <a class="menu-buttons" href="operational-overload.html">30. Embedding
          an SRE to Recover from Operational Overload</a>
        </li>
        <li class='active'>
          <a class="menu-buttons" href=
          "communication-and-collaboration.html">31. Communication and
          Collaboration in SRE</a>
        </li>
        <li>
          <a class="menu-buttons" href="evolving-sre-engagement-model.html">32.
          The Evolving SRE Engagement Model</a>
        </li>
        <li>
          <a class="menu-buttons" href="part5.html">Part V - Conclusions</a>
        </li>
        <li>
          <a class="menu-buttons" href="lessons-learned.html">33. Lessons
          Learned from Other Industries</a>
        </li>
        <li>
          <a class="menu-buttons" href="conclusion.html">34. Conclusion</a>
        </li>
        <li>
          <a class="menu-buttons" href="availability-table.html">Appendix A.
          Availability Table</a>
        </li>
        <li>
          <a class="menu-buttons" href="service-best-practices.html">Appendix B.
          A Collection of Best Practices for Production Services</a>
        </li>
        <li>
          <a class="menu-buttons" href="incident-document.html">Appendix C.
          Example Incident State Document</a>
        </li>
        <li>
          <a class="menu-buttons" href="postmortem.html">Appendix D. Example
          Postmortem</a>
        </li>
        <li>
          <a class="menu-buttons" href="launch-checklist.html">Appendix E.
          Launch Coordination Checklist</a>
        </li>
        <li>
          <a class="menu-buttons" href="bibliography.html">Appendix F.
          Bibliography</a>
        </li>
      </ol>
    </div>
    <div id="maia-main" role="main">
      <div class="maia-teleport" id="content"></div>
      <div class="content">
        <section data-type="chapter" id="chapter_comms-collab">
          <h1 class="heading">
            Communication and Collaboration in SRE
          </h1>
          <p class="byline author">
            Written by Niall Murphy with Alex Rodriguez, Carl Crous, Dario Freni, Dylan Curley,
            Lorenzo Blanco, and Todd Underwood<br>
            Edited by Betsy Beyer
          </p>
          <p>
            <a data-primary="Site Reliability Engineering (SRE)" data-secondary=
            "Google's approach to management" data-type="indexterm" id=
            "id-nxC1Sptb"></a><a data-primary="communication and collaboration" data-secondary=
            "position of SRE in Google" data-type="indexterm" id="id-NnC7F9t4"></a>The
            organizational position of SRE in Google is interesting, and has effects on how we
            communicate and collaborate.
          </p>
          <p>
            To begin with, there is a tremendous diversity in what SRE does, and how we do it. We
            have infrastructural teams, service teams, and horizontal product teams. We have
            relationships with product development teams ranging from teams that are many times our
            size, to teams roughly the same size as their counterparts, and situations in which we
            <em>are</em> the product development team. SRE teams are made up of people with systems
            engineering or architectural skills (see <a data-type="xref" href=
            "bibliography.html#Hix15b" target="_blank">[Hix15b]</a>), software
            engineering skills, project management skills, leadership instincts, backgrounds in all
            kinds of industries (see <a data-type="xref" href=
            "lessons-learned.html">Lessons Learned from Other Industries</a>),
            and so on. We don't have just one model, and we have found a variety of configurations
            that work; this flexibility suits our ultimately pragmatic nature.
          </p>
          <p>
            It's also true that SRE is not a command-and-control organization. Generally, we owe
            allegiance to at least two masters: for service or infrastructure SRE teams, we work
            closely with the corresponding product development teams that work on those services or
            that infrastructure; we also obviously work in the context of SRE generally. The
            service relationship is very strong, since we are held accountable for the performance
            of those systems, but despite that relationship, our actual reporting lines are through
            SRE as a whole. Today, we spend more time supporting our individual services than on
            cross-production work, but our culture and our shared values produce strongly
            homogeneous approaches to problems. This is by design.<sup><a data-type="noteref" href=
            "communication-and-collaboration.html#id-rq7uXSATe" id="id-rq7uXSATe-marker">146</a></sup>
          </p>
          <p>
            The two preceding facts have steered the SRE organization in certain directions when it
            comes to two crucial dimensions of how our teams operate—communications and
            collaboration. Data flow would be an apt computing metaphor for our communications:
            just like data must flow around production, data also has to flow around an SRE
            team—data about projects, the state of the services, production, and the state of the
            individuals. For maximum effectiveness of a team, the data has to flow in reliable ways
            from one interested party to another. One way to think of this flow is to think of the
            interface that an SRE team must present to other teams, such as an API. Just like an
            API, a good design is crucial for effective operation, and if the API is wrong, it can
            be painful to correct later on.
          </p>
          <p>
            The API-as-contract metaphor is also relevant for collaboration, both among SRE teams,
            and between SRE and product development teams—all have to make progress in an
            environment of unrelenting change. To that extent, our collaboration looks quite like
            collaboration in any other fast-moving company. The difference is the mix of software
            engineering skills, systems engineering expertise, and the wisdom of production
            experience that SRE brings to bear on that collaboration. The best designs and the best
            implementations result from the joint concerns of production and the product being met
            in an atmosphere of mutual respect. This is the promise of SRE: an organization charged
            with reliability, with the same skills as the product development teams, will improve
            things measurably. Our experience suggests that simply having someone in charge of
            reliability, without also having the complete skill set, is not enough.
          </p>
          <section data-type="sect1" id="xref_comms-collab_production-meetings">
            <h1 class="heading">
              Communications: Production Meetings
            </h1>
            <p>
              <a data-primary="communication and collaboration" data-secondary=
              "production meetings" data-see="production meetings" data-type="indexterm" id=
              "id-MnCNS0FEud"></a><a data-primary="production meetings" data-type="indexterm" id=
              "CCproduct31"></a>Although literature about running effective meetings abounds
              <a data-type="xref" href="bibliography.html#Kra08" target=
              "_blank">[Kra08]</a>, it's difficult to find someone who's lucky enough to
              <em>only</em> have useful, effective meetings. This is equally true for SRE.
            </p>
            <p>
              However, there's one kind of meeting that we have that is more useful than the
              average, called a <em>production meeting</em>. Production meetings are a special kind
              of meeting where an SRE team carefully articulates to itself—and to its invitees—the
              state of the service(s) in their charge, so as to increase general awareness among
              everyone who cares, and to improve the operation of the service(s). In general, these
              meetings are <em>service-oriented</em>; they are not directly about the status
              updates of individuals. The goal is for everyone to leave the meeting with an idea of
              what's going on—the <em>same</em> idea. The other major goal of production meetings
              is to improve our services by bringing the wisdom of production to bear on our
              services. That means we talk in detail about the operational performance of the
              service, and relate that operational performance to design, configuration, or
              implementation, and make recommendations for how to fix the problems. Connecting the
              performance of the service with design decisions in a regular meeting is an immensely
              powerful feedback loop.
            </p>
            <p>
              Our production meetings usually happen weekly; given SRE's antipathy to pointless
              meetings, this frequency seems to be just about right: time to allow enough relevant
              material to accumulate to make the meeting worthwhile, while not so frequent that
              people find excuses to not attend. They usually last somewhere between 30 and 60
              minutes. Any less and you're probably cutting something unnecessarily short, or you
              should probably be growing your service portfolio. Any more and you're probably
              getting mired in the detail, or you've got too much to talk about and you should
              shard the team or service set.
            </p>
            <p>
              Just like any other meeting, the production meeting should have a chair. Many SRE
              teams rotate the chair through various team members, which has the advantage of
              making everyone feel they have a stake in the service and some notional ownership of
              the issues. It's true that not everyone has equal levels of chairing skill, but the
              value of group ownership is so large that the trade-off of temporary suboptimality is
              worthwhile. Furthermore, this is a chance to instill chairing skills, which are very
              useful in the kind of incident coordination situations commonly faced by SRE.
            </p>
            <p>
              In cases where two SRE teams are meeting by video, and one of the teams is much
              larger than the other, we have noticed an interesting dynamic at play. We recommend
              placing your chair on the <em>smaller</em> side of the call by default. The larger
              side naturally tends to quiet down and some of the bad effects of imbalanced team
              sizes (made worse by the delays inherent in video conferencing) will
              improve.<sup><a data-type="noteref" href="communication-and-collaboration.html#id-oAdukFqT7uz" id=
              "id-oAdukFqT7uz-marker">147</a></sup> We have no idea if this technique has any
              scientific basis, but it does tend to work.
            </p>
            <section data-type="sect2" id="agenda-rWsNcpue">
              <h2 class="subheaders">
                Agenda
              </h2>
              <p>
                There are many ways to run a production meeting, attesting to the diversity of what
                SRE looks after and how we do it. To that extent, it's not appropriate to be
                prescriptive on how to run one of these meetings. However, a default agenda (see
                <a data-type="xref" href=
                "launch-checklist.html#appendix_effective-meetings">Example
                Production Meeting Minutes</a> for an example) might look something like the
                following:
              </p>
              <dl>
                <dt class="dt-heading">
                  Upcoming production changes
                </dt>
                <dd>
                  <p>
                    Change-tracking meetings are well known throughout the industry, and indeed
                    whole meetings have often been devoted to stopping change. However, in our
                    production environment, we usually default to enabling change, which requires
                    tracking the useful set of properties of that change: start time, duration,
                    expected effect, and so on. This is near-term horizon visibility.
                  </p>
                </dd>
              </dl>
              <dl class="pagebreak-before">
                <dt class="dt-heading">
                  Metrics
                </dt>
                <dd>
                  <p>
                    One of the major ways we conduct a service-oriented discussion is by talking
                    about the core metrics of the systems in question; see <a data-type="xref"
                    href="service-level-objectives.html">Service Level
                    Objectives</a>. Even if the systems didn't dramatically fail that week, it's
                    very common to be in a position where you're looking at gradually (or sharply!)
                    increasing load throughout the year. Keeping track of how your latency figures,
                    CPU utilization figures, etc., change over time is incredibly valuable for
                    developing a feeling for the performance envelope of a system.
                  </p>
                  <p>
                    Some teams track resource usage and efficiency, which is also a useful
                    indicator of slower, perhaps more insidious system changes.
                  </p>
                </dd>
                <dt class="dt-heading">
                  Outages
                </dt>
                <dd>
                  <p>
                    This item addresses problems of approximately postmortem size, and is an
                    indispensable opportunity for learning. A good postmortem analysis, as
                    discussed in <a data-type="xref" href=
                    "postmortem-culture.html">Postmortem Culture: Learning from
                    Failure</a>, should always set the juices flowing.
                  </p>
                </dd>
                <dt class="dt-heading">
                  Paging events
                </dt>
                <dd>
                  <p>
                    These are pages from your monitoring system, relating to problems that
                    <em>can</em> be postmortem worthy, but often aren't. In any event, while the
                    Outages portion looks at the larger picture of an outage, this section looks at
                    the tactical view: the list of pages, who was paged, what happened then, and so
                    on. There are two implicit questions for this section: should that alert have
                    paged in the way it did, and should it have paged at all? If the answer to the
                    last question is no, remove those unactionable pages.
                  </p>
                </dd>
                <dt class="dt-heading">
                  Nonpaging events
                </dt>
                <dd>
                  <p>
                    This bucket contains three items:
                  </p>
                  <ul>
                    <li>
                      <em>An issue that probably should have paged, but didn't</em>. In these
                      cases, you should probably fix the monitoring so that such events do trigger
                      a page. Often you encounter the issue while you're trying to fix something
                      else, or it's related to a metric you're tracking but for which you haven't
                      got an alert.
                    </li>
                    <li>
                      <em>An issue that is not pageable but requires attention</em>, such as
                      low-impact data corruption or slowness in some non-user-facing dimension of
                      the system. Tracking reactive operational work is also appropriate here.
                    </li>
                    <li>
                      <em>An issue that is not pageable and does not require attention</em>. These
                      alerts should be removed, because they create extra noise that distracts
                      engineers from issues that do merit attention.
                    </li>
                  </ul>
                </dd>
              </dl>
              <dl class="pagebreak-before">
                <dt class="dt-heading">
                  Prior action items
                </dt>
                <dd>
                  <p>
                    The preceding detailed discussions often lead to actions that SRE needs to
                    take—fix this, monitor that, develop a subsystem to do the other. Track these
                    improvements just as they would be tracked in any other meeting: assign action
                    items to people and track their progress. It's a good idea to have an explicit
                    agenda item that acts as a catchall, if nothing else. Consistent delivery is
                    also a wonderful credibility and trust builder. It doesn't matter how such
                    delivery is done, just that it <em>is</em> done.
                  </p>
                </dd>
              </dl>
            </section>
            <section data-type="sect2" id="attendance-wPsNiau2">
              <h2 class="subheaders">
                Attendance
              </h2>
              <p>
                Attendance is compulsory for all the members of the SRE team in question. This is
                particularly true if your team is spread across multiple countries and/or time
                zones, because this is your major opportunity to interact as a group.
              </p>
              <p>
                The major stakeholders should also attend this meeting. Any partner product
                development teams you may have should also attend. Some SRE teams shard their
                meeting so SRE-only matters are kept to the first half; that practice is fine, as
                long as everyone, as stated previously, leaves with the same idea of what's going
                on. From time to time representatives from other SRE teams might turn up,
                particularly if there's some larger cross-team issue to discuss, but in general,
                the SRE team in question plus major other teams should attend. If your relationship
                is such that you cannot invite your product development partners, you need to fix
                that relationship: perhaps the first step is to invite a representative from that
                team, or to find a trusted intermediary to proxy communication or model healthy
                interactions. There are many reasons why teams don't get along, and a wealth of
                writing on how to solve that problem: this information is also applicable to SRE
                teams, but it is important that the end goal of having a feedback loop from
                operations is fulfilled, or a large part of the value of having an SRE team is
                lost.
              </p>
              <p>
                Occasionally you'll have too many teams or busy-yet-crucial attendees to invite.
                There are a number of techniques you can use to handle those situations:
              </p>
              <ul>
                <li>Less active services might be attended by a single representative from the
                product development team, or only have commitment from the product development team
                to read and comment on the agenda minutes.
                </li>
                <li>If the production development team is quite large, nominate a subset of
                representatives.
                </li>
                <li>Busy-yet-crucial attendees can provide feedback and/or steering in advance to
                individuals, or using the prefilled agenda technique (described next).
                </li>
              </ul>
              <p class="pagebreak-before">
                Most of the meeting strategies we've discussed are common sense, with a
                service-oriented twist. One unique spin on making meetings more efficient
                <em>and</em> more inclusive is to use the real-time collaborative features of
                Google Docs. Many SRE teams have such a doc, with a well-known address that anyone
                in engineering can access. Having such a doc enables two great practices:
              </p>
              <ul>
                <li>Pre-populating the agenda with "bottom up" ideas, comments, and information.
                </li>
                <li>Preparing the agenda in parallel <em>and</em> in advance is really efficient.
                </li>
              </ul>
              <p>
                Fully use the multiple-person collaboration features enabled by the product.
                There's nothing quite like seeing a meeting chair type in a sentence, then seeing
                someone else supply a link to the source material in brackets after they have
                finished typing, and then seeing yet another person tidy up the spelling and
                grammar in the original sentence. Such collaboration gets stuff done faster, and
                makes more people feel like they own a slice of what the team does.<a data-primary=
                "" data-startref="CCproduct31" data-type="indexterm" id="id-DnC1SVi1iauz"></a>
              </p>
            </section>
          </section>
          <section data-type="sect1" id="collaboration-within-sre-9psZUW">
            <h1 class="heading">
              Collaboration within SRE
            </h1>
            <p>
              <a data-primary="communication and collaboration" data-secondary="within SRE team"
              data-type="indexterm" id="id-7nCJSgF9U2"></a>Obviously, Google is a multinational
              organization. Because of the emergency response and pager rotation component of our
              role, we have very good business reasons to be a distributed organization, separated
              by at least a few time zones. The practical impact of this distribution is that we
              have very fluid definitions for "team" compared to, for example, the average product
              development team. We have local teams, the team on the site, the cross-continental
              team, virtual teams of various sizes and coherence, and everything in between. This
              creates a cheerfully chaotic mix of responsibilities, skills, and opportunities. Much
              of the same dynamics could be expected to pertain to any sufficiently large company
              (although they might be particularly intense for tech companies). Given that most
              local collaboration faces no particular obstacle, the interesting case
              collaboration-wise is cross-team, cross-site, across a virtual team, and similar.
            </p>
            <p>
              This pattern of distribution also informs how SRE teams tend to be organized. Because
              our <em>raison d'être</em> is bringing value through technical mastery, and technical
              mastery tends to be hard, we therefore try to find a way to have mastery over some
              related subset of systems or infrastructures, in order to decrease cognitive load.
              Specialization is one way of accomplishing this objective; i.e., team X works only on
              product Y. Specialization is good, because it leads to higher chances of improved
              technical mastery, but it's also bad, because it leads to siloization and ignorance
              of the broader picture. We try to have a crisp team charter to define what a team
              will—and more importantly, won't—support, but we don't always succeed.
            </p>
            <section data-type="sect2" id="team-composition-yDsgtmUq">
              <h2 class="subheaders">
                Team Composition
              </h2>
              <p>
                We have a wide array of skill sets in SRE, ranging from systems engineering through
                software engineering, and into organization and management. The one thing we can
                say about collaboration is that your chances of successful collaboration—and indeed
                just about anything else—are improved by having more diversity in your team.
                There's a lot of evidence suggesting that diverse teams are simply better teams
                <a data-type="xref" href="bibliography.html#Nel14" target=
                "_blank">[Nel14]</a>. Running a diverse team implies particular attention to
                communication, cognitive biases, and so on, which we can't cover in detail here.
              </p>
              <p>
                Formally, SRE teams have the roles of "tech lead" (TL), "manager" (SRM), and
                "project manager" (also known as PM, TPM, PgM). Some people operate best when those
                roles have well-defined responsibilities: the major benefit of this being they can
                make in-scope decisions quickly and safely. Others operate best in a more fluid
                environment, with shifting responsibilities depending on dynamic negotiation. In
                general, the more fluid the team is, the more developed it is in terms of the
                capabilities of the individuals, and the more able the team is to adapt to new
                situations—but at the cost of having to communicate more and more often, because
                less background can be assumed.
              </p>
              <p>
                Regardless of how well these roles are defined, at a base level the tech lead is
                responsible for technical direction in the team, and can lead in a variety of
                ways—everything from carefully commenting on everyone's code, to holding quarterly
                direction presentations, to building consensus in the team. In Google, TLs can do
                almost all of a manager's job, because our managers are highly technical, but the
                manager has two special responsibilities that a TL doesn't have: the performance
                management function, and being a general catchall for everything that isn't handled
                by someone else. Great TLs, SRMs, and TPMs have a complete set of skills and can
                cheerfully turn their hand to organizing a project, commenting on a design doc, or
                writing code as necessary.
              </p>
            </section>
            <section data-type="sect2" id="techniques-for-working-effectively-V7sohqU2">
              <h2 class="subheaders">
                Techniques for Working Effectively
              </h2>
              <p>
                There are a number of ways to engineer effectively in SRE.
              </p>
              <p>
                In general, singleton projects fail unless the person is particularly gifted or the
                problem is straightforward. To accomplish anythingsignificant, you pretty much need
                multiple people. Therefore, you also need good collaboration skills. Again, lots of
                material has been written on this topic, and much of this literature is applicable
                to SRE.
              </p>
              <p>
                In general, good SRE work calls for excellent communication skills when you're
                working outside the boundary of your purely local team. For collaborations outside
                the building, effectively working across time zones implies either great written
                communication, or lots of travel to supply the in-person experience that is
                deferrable but ultimately necessary for a high-quality relationship. Even if you're
                a great writer, over time you decay into just being an email address until you turn
                up in the flesh again.
              </p>
            </section>
          </section>
          <section data-type="sect1" id="case-study-of-collaboration-in-sre-viceroy-ZKsVCZ">
            <h1 class="heading">
              Case Study of Collaboration in SRE: Viceroy
            </h1>
            <p>
              <a data-primary="communication and collaboration" data-secondary="case studies"
              data-type="indexterm" id="CCviceroy31"></a><a data-primary="Viceroy project"
              data-type="indexterm" id="viceroy31"></a>One example of a successful cross-SRE
              collaboration is a project called Viceroy, which is a monitoring dashboard framework
              and service. The current organizational architecture of SRE can end up with teams
              producing multiple, slightly different copies of the same piece of work; for various
              reasons, monitoring dashboard frameworks were a particularly fertile ground for
              duplication of work.<sup><a data-type="noteref" href="communication-and-collaboration.html#id-p8BuZIjFLC0" id=
              "id-p8BuZIjFLC0-marker">148</a></sup>
            </p>
            <p>
              The incentives that led to the serious litter problem of many smoldering, abandoned
              hulks of monitoring frameworks lying around were pretty simple: each team was
              rewarded for developing its own solution, working outside of the team boundary was
              hard, and the infrastructure that tended to be provided SRE-wide was typically closer
              to a toolkit than a product. This environment encouraged individual engineers to use
              the toolkit to make another burning wreck rather than fix the problem for the largest
              number of people possible (an effort that would therefore take much longer).
            </p>
            <section data-type="sect2" id="the-coming-of-the-viceroy-V7s2tnC2">
              <h2 class="subheaders">
                The Coming of the Viceroy
              </h2>
              <p>
                Viceroy was different. It began in 2012 when a number of teams were considering how
                to move to Monarch, the new monitoring system at Google. SRE is deeply conservative
                with respect to monitoring systems, so Monarch somewhat ironically took a longer
                while to get traction within SRE than within non-SRE teams. But no one could argue
                that our legacy monitoring system, Borgmon (see <a data-type="xref" href=
                "practical-alerting.html">Practical Alerting from Time-Series
                Data</a>), had no room for improvement. For example, our consoles were cumbersome
                because they used a custom HTML templating system that was special-cased, full of
                funky edge cases, and difficult to test. At that time, Monarch had matured enough
                to be accepted in principle as the replacement for the legacy system and was
                therefore being adoptedby more and more teams across Google, but it turned out we
                still had a problem with consoles.
              </p>
              <p>
                Those of us who tried using Monarch for our services soon found that it fell short
                in its console support for two main reasons:
              </p>
              <ul>
                <li>Consoles were easy to set up for a small service, but didn't scale well to
                services with complex consoles.
                </li>
                <li>They also didn't support the legacy monitoring system, making the transition to
                Monarch very difficult.
                </li>
              </ul>
              <p>
                Because no viable alternative to deploying Monarch in this way existed at the time,
                a number of team-specific projects launched. Since there was little enough in the
                way of coordinated development solutions or even cross-group tracking at the time
                (a problem that has since been fixed), we ended up duplicating efforts yet again.
                Multiple teams from Spanner, Ads Frontend, and a variety of other services spun up
                their own efforts (one notable example was called Consoles++) over the course of
                12–18 months, and eventually sanity prevailed when engineers from all those teams
                woke up and discovered each other's respective efforts. They decided to do the
                sensible thing and join forces in order to create a general solution for all of
                SRE. Thus, the Viceroy project was born in mid 2012.
              </p>
              <p>
                By the beginning of 2013, Viceroy had started to gather interest from teams who had
                yet to move off the legacy system, but who were looking to put a toe in the water.
                Obviously, teams with larger existing monitoring projects had fewer incentives to
                move to the new system: it was hard for these teams to rationalize jettisoning the
                low maintenance cost for their existing solution that basically worked fine, for
                something relatively new and unproven that would require lots of effort to make
                work. The sheer diversity of requirements added to the reluctance of these teams,
                even though all monitoring console projects shared two main requirements, notably:
              </p>
              <ul>
                <li>Support complex curated dashboards
                </li>
                <li>Support both Monarch and the legacy monitoring system
                </li>
              </ul>
              <p>
                Each project <em>also</em> had its own set of technical requirements, which
                depended on the author's preference or experience. For example:
              </p>
              <ul>
                <li>Multiple data sources outside the core monitoring systems
                </li>
                <li>Definition of consoles using configuration versus explicit HTML layout
                </li>
                <li>No JavaScript versus full embrace of JavaScript with AJAX
                </li>
                <li>Sole use of static content, so the consoles can be cached in the browser
                </li>
              </ul>
              <p>
                Although some of these requirements were stickier than others, overall they made
                merging efforts difficult. Indeed, although the Consoles++ team was interested in
                seeing how their project compared to Viceroy, their initial examination in the
                first half of 2013 determined that the fundamental differences between the two
                projects were significant enough to prevent integration. The largest difficulty was
                that Viceroy by design did not use much JavaScript, while Consoles++ was mostly
                written in JavaScript. There was a glimmer of hope, however, in that the two
                systems did have a number of underlying similarities:
              </p>
              <ul class="pagebreak-before">
                <li>They used similar syntaxes for HTML template rendering.
                </li>
                <li>They shared a number of long-term goals, which neither team had yet begun to
                address. For example, both systems wanted to cache monitoring data and support an
                offline pipeline to periodically produce data that the console can use, but was too
                computationally expensive to produce on demand.
                </li>
              </ul>
              <p>
                We ended up parking the unified console discussion for a while. However, by the end
                of 2013, both Consoles++ and Viceroy had developed significantly. Their technical
                differences had narrowed, because Viceroy had started using JavaScript to render
                its monitoring graphs. The two teams met and figured out that integration was a lot
                easier, now that integration boiled down to serving the Consoles++ data out of the
                Viceroy server. The first integrated prototypes were completed in early 2014, and
                proved that the systems could work well together. Both teams felt comfortable
                committing to a joint effort at that point, and because Viceroy had already
                established its brand as a common monitoring solution, the combined project
                retained the Viceroy name. Developing full functionality took a few quarters, but
                by the end of 2014, the combined system was complete.
              </p>
              <p>
                Joining forces reaped huge benefits:
              </p>
              <ul>
                <li>Viceroy received a host of data sources and the JavaScript clients to access
                them.
                </li>
                <li>JavaScript compilation was rewritten to support separate modules that can be
                selectively included. This is essential to scale the system to any number of teams
                with their own JavaScript code.
                </li>
                <li>Consoles++ benefited from the many improvements actively being made to Viceroy,
                such as the addition of its cache and background data pipeline.
                </li>
                <li>Overall, the development velocity on <em>one</em> solution was much larger than
                the sum of all the development velocity of the duplicative projects.
                </li>
              </ul>
              <p>
                Ultimately, the common future vision was the key factor in combining the projects.
                Both teams found value in expanding their development team and benefited from each
                other's contributions. The momentum was such that, by the end of 2014, Viceroy was
                officially declared the general monitoring solution for all of SRE. Perhaps
                characteristically for Google, this declaration didn't require that teams adopt
                Viceroy: rather, it recommended that teams should use Viceroy instead of writing
                another monitoring console.
              </p>
            </section>
            <section data-type="sect2" id="challenges-rWsZh0Ce">
              <h2 class="subheaders">
                Challenges
              </h2>
              <p>
                While ultimately a success, Viceroy was not without difficulties, and many of those
                arose due to the cross-site nature of the project.
              </p>
              <p>
                Once the extended Viceroy team was established, initial coordination among remote
                team members proved difficult. When meeting people for the first time, subtle cues
                in writing and speaking can be misinterpreted, because communication styles vary
                substantially from person to person. At the start of the project, team members who
                weren't located in Mountain View also missed out on the impromptu water cooler
                discussions that often happened shortly before and after meetings (although
                communication has since improved considerably).
              </p>
              <p>
                While the core Viceroy team remained fairly consistent, the extended team of
                contributors was fairly dynamic. Contributors had other responsibilities that
                changed over time, and therefore many were able to dedicate between one and three
                months to the project. Thus, the developer contributor pool, which was inherently
                larger than the core Viceroy team, was characterized by a significant amount of
                churn.
              </p>
              <p>
                Adding new people to the project required training each contributor on the overall
                design and structure of the system, which took some time. On the other hand, when
                an SRE contributed to the core functionality of Viceroy and later returned to their
                own team, they were a local expert on the system. That unanticipated dissemination
                of local Viceroy experts drove more usage and adoption.
              </p>
              <p>
                As people joined and left the team, we found that casual contributions were both
                useful and costly. The primary cost was the dilution of ownership: once features
                were delivered and the person left, the features became unsupported over time, and
                were generally dropped.
              </p>
              <p>
                Furthermore, the scope of the Viceroy project grew over time. It had ambitious
                goals at launch but the initial <em>scope</em> was limited. As the scope grew,
                however, we struggled to deliver core features on time, and had to improve project
                management and set clearer direction to ensure the project stayed on track.
              </p>
              <p>
                Finally, the Viceroy team found it difficult to completely own a component that had
                significant (determining) contributions from distributed sites. Even with the best
                will in the world, people generally default to the path of least resistance and
                discuss issues or make decisions locally without involving the remote owners, which
                can lead to conflict.
              </p>
            </section>
            <section data-type="sect2" id="recommendations-wPsvT0C2">
              <h2 class="subheaders">
                Recommendations
              </h2>
              <p>
                You should only develop projects cross-site when you have to, but often there are
                good reasons to have to. The cost of working across sites is higher latency for
                actions and more communication being required; the benefit is—if you get the
                mechanics right—much higher throughput. The single site project can also fall foul
                of no one outside of that site knowing what you're doing, so there are costs to
                both approaches.
              </p>
              <p>
                Motivated contributors are valuable, but not all contributions are equally
                valuable. Make sure project contributors are actually committed, and aren't just
                joining with some nebulous self-actualization goal (wanting to earn a notch on
                their belt attaching their name to a shiny project; wanting to code on a new
                exciting project without committing to maintaining that project). Contributors with
                a specific goal to achieve will generally be better motivated and will better
                maintain their contributions.
              </p>
              <p>
                As projects develop, they usually grow, and you're not always in the lucky position
                of having people in your local team to contribute to the project. Therefore, think
                carefully about the project structure. The project leaders are important: they
                provide long-term vision for the project and make sure all work aligns with that
                vision and is prioritized correctly. You also need to have an agreed way of making
                decisions, and should specifically optimize for making more decisions locally if
                there is a high level of agreement and trust.
              </p>
              <p>
                The standard "divide and conquer" strategy applies to cross-site projects; you
                reduce communication costs primarily by splitting the project into as many
                reasonably sized components as possible, and trying to make sure that each
                component can be assigned to a small group, preferably within one site. Divide
                these components among the project subteams, and establish clear deliverables and
                deadlines. (Try not to let Conway's law distort the natural shape of the software
                too deeply.)<sup><a data-type="noteref" href="communication-and-collaboration.html#id-vkKuPSPhMTpC4" id=
                "id-vkKuPSPhMTpC4-marker">149</a></sup>
              </p>
              <p>
                A goal for a project team works best when it's oriented toward providing some
                functionality or solving some problem. This approach ensures that the individuals
                working on a component know what is expected of them, and that their work is only
                complete once that component is fully integrated and used within the main project.
              </p>
              <p>
                Obviously, the usual engineering best practices apply to collaborative projects:
                each component should have design documents and reviews with the team. In this way,
                everyone in the team is given the opportunity to stay abreast of changes, in
                addition to the chance to influence and improve designs. Writing things down is one
                of the major techniques you have to offset physical and/or logical distance—use it.
              </p>
              <p>
                Standards are important. Coding style guidelines are a good start, but they're
                usually quite tactical and therefore only a starting point for establishing team
                norms. Every time there is a debate around which choice to make on an issue, argue
                it out fully with the team but with a strict time limit. Then pick a solution,
                document it, and move on. If you can't agree, you need to pick some arbitrator that
                everyone respects, and again just move forward. Over time you'll build up a
                collection of these best practices, which will help new people come up to speed.
              </p>
              <p>
                Ultimately, there's no substitute for in-person interaction, although some portion
                of face-to-face interaction can be deferred by good use of VC and good written
                communication. If you can, have the leaders of the project meet the rest of the
                team in person. If time and budget allows, organize a team summit so that all
                members of the team can interact in person. A summit also provides a great
                opportunity to hash out designs and goals. For situations where neutrality is
                important, it's advantageous to hold team summits at a neutral location so that no
                individual site has the "home advantage."
              </p>
              <p>
                Finally, use the project management style that suits the project in its current
                state. Even projects with ambitious goals will start out small, so the overhead
                should be correspondingly low. As the project grows, it's appropriate to adapt and
                change how the project is managed. Given sufficient growth, full project management
                will be <span class="keep-together">necessary</span>.<a data-primary=""
                data-startref="viceroy31" data-type="indexterm" id="id-JnCzFMU2T2CW"></a>
              </p>
            </section>
          </section>
          <section data-type="sect1" id="collaboration-outside-sre-zVsos4">
            <h1 class="heading">
              Collaboration Outside SRE
            </h1>
            <p>
              <a data-primary="communication and collaboration" data-secondary="outside SRE team"
              data-type="indexterm" id="id-QnCkSXFBsP"></a>As we suggested, and <a data-type="xref"
              href="evolving-sre-engagement-model.html">The Evolving SRE
              Engagement Model</a> discusses, collaboration between the product development
              organization and SRE is really at its best when it occurs early on in the design
              phase, ideally before any line of code has been committed. SREs are best placed to
              make recommendations about architecture and software behavior that can be quite
              difficult (if not impossible) to retrofit. Having that voice present in the room when
              a new system is being designed goes better for everyone. Broadly speaking, we use the
              Objectives &amp; Key Results (OKR) process <a data-type="xref" href=
              "bibliography.html#Kla12" target="_blank">[Kla12]</a> to track
              such work. For some service teams, such collaboration is the mainstay of what they
              do—tracking new designs, making recommendations, helping to implement them, and
              seeing those through to production.
            </p>
          </section>
          <section data-type="sect1" id="case-study-migrating-dfp-to-f1-yDsDHn">
            <h1 class="heading">
              Case Study: Migrating DFP to F1
            </h1>
            <p>
              <a data-primary="DoubleClick for Publishers (DFP)" data-type="indexterm" id=
              "dfp31"></a><a data-primary="MySQL" data-secondary="migrating" data-type="indexterm"
              id="id-KnCdFeFvHk"></a>Large migration projects of existing services are quite common
              at Google. Typical examples include porting service components to a new technology or
              updating components to support a new data format. With the recent introduction of
              database technologies that can scale to a global level such as Spanner <a data-type=
              "xref" href="bibliography.html#Cor12" target="_blank">[Cor12]</a>
              and F1 <a data-type="xref" href="bibliography.html#Shu13" target=
              "_blank">[Shu13]</a>, Google has undertaken a number of large-scale migration
              projects involving databases. One such project was the migration of the main database
              of DoubleClick for Publishers (DFP)<sup><a data-type="noteref" href="communication-and-collaboration.html#id-12pS9hqFpHp"
              id="id-12pS9hqFpHp-marker">150</a></sup> from MySQL to F1. In particular, some of
              this chapter's authors were in charge of a portion of the serving system (shown in
              <a data-type="xref" href="communication-and-collaboration.html#fig_comms-collab_ads-serving">Figure 31-1</a>) that
              continually extracts and processes data from the database, in order to generate a set
              of indexed files that are then loaded and served around the world. This system was
              distributed over several datacenters and used about 1,000 CPUs and 8 TB of RAM to
              index 100 TB of data every day.
            </p>
            <figure class="horizontal vertical" id="fig_comms-collab_ads-serving">
              <img alt="A generic ads serving system." src="../images/srle-3101.jpg">
              <figcaption>
                <span class="label">Figure 31-1.</span> A generic ads serving system
              </figcaption>
            </figure>
            <p>
              The migration was nontrivial: in addition to migrating to a new technology, the
              database schema was significantly refactored and simplified thanks to the ability of
              F1 to store and index protocol buffer data in table columns. The goal was to migrate
              the processing system so that it could produce an output perfectly identical to the
              existing system. This allowed us to leave the serving system untouched and to
              perform, from the user's perspective, a seamless migration. As an added restriction,
              the product required that we complete a live migration without any disruption of the
              service to our users at any time. In order to achieve this, the product development
              team and the SRE team started working closely, from the very beginning, to develop
              the new indexing service.
            </p>
            <p>
              As its main developers, product development teams are typically more familiar with
              the Business Logic (BL) of the software, and are also in closer contact with the
              Product Managers and the actual "business need" component of products. On the other
              hand, SRE teams usually have more expertise pertaining to the infrastructure
              components of the software (e.g., libraries to talk to distributed storage systems or
              databases), because SREs often reuse the same building blocks across different
              services, learning the many caveats and nuances that allow the software to run
              scalably and reliably over time.
            </p>
            <p>
              From the start of the migration project, product development and SRE knew they would
              have to collaborate even more closely, conducting weekly meetings to sync on the
              project's progress. In this particular case the BL changes were partially dependent
              upon infrastructure changes. For this reason the project started with the design of
              the new infrastructure; the SREs, who had extensive knowledge about the domain of
              extracting and processing data at scale, drove the design of the infrastructure
              changes. This involved designing how to extract the various tables from F1, how to
              filter and join the data, how to extract only the data that changed (as opposed to
              the entire database), how to sustain the loss of some of the machines without
              impacting the service, how to ensure that the resource usage grows linearly with the
              amount of extracted data, the capacity planning, and many other similar aspects. The
              new proposed infrastructure was similar to other services that were already
              extracting and processing data from F1. Therefore, we could be sure of the soundness
              of the solution and reuse parts of the monitoring and tooling.
            </p>
            <p>
              Before proceeding with the development of this new infrastructure, two SREs produced
              a detailed design document. Then, both the product development and SRE teams
              thoroughly reviewed the document, tweaking the solution to handle some edge cases,
              and eventually agreed on a design plan. Such a plan clearly identified what kind of
              changes the new infrastructure would bring to the BL. For example, we designed the
              new infrastructure to extract only changed data, instead of repeatedly extracting the
              entire database; the BL had to take into account this new approach. Early on, we
              defined the new interfaces between infrastructure and BL, and doing so allowed the
              product development team to work independently on the BL changes. Similarly, the
              product development team kept SRE informed of BL changes. Where they interacted
              (e.g., BL changes dependent on infrastructure), this coordination structure allowed
              us to know changes were happening, and to handle them quickly and correctly.
            </p>
            <p>
              In later phases of the project, SREs began deploying the new service in a testing
              environment that resembled the project's eventual finished production environment.
              This step was essential to measure the expected behavior of the service—in
              particular, performance and resource utilization—while the development of BL was
              still underway. The product development team used this testing environment to perform
              validation of the new service: the index of the ads produced by the old service
              (running in production) had to match perfectly the index produced by the new service
              (running in the testing environment). As suspected, the validation process
              highlighted discrepancies between the old and new services (due to some edge cases in
              the new data format), which the product development team was able to resolve
              iteratively: for each ad they debugged the cause of the difference and fixed the BL
              that produced the bad output. In the meantime, the SRE team began preparing the
              production environment: allocating the necessary resources in a different datacenter,
              setting up processes and monitoring rules, and training the engineers designated to
              be on-call for the service. The SRE team also set up a basic release process that
              included validation, a task usually completed by the product development team or by
              Release Engineers but in this specific case was completed by SREs to speed up the
              migration.
            </p>
            <p>
              When the service was ready the SREs prepared a rollout plan in collaboration with the
              product development team and launched the new service. The launch was very successful
              and proceeded smoothly, without any visible user impact.<a data-primary=""
              data-startref="CCviceroy31" data-type="indexterm" id=
              "id-e4CzSNu7H8"></a><a data-primary="" data-startref="dfp31" data-type="indexterm"
              id="id-GnCZFbuZHD"></a>
            </p>
          </section>
          <section data-type="sect1" id="conclusion-V7szfP">
            <h1 class="heading">
              Conclusion
            </h1>
            <p>
              <a data-primary="communication and collaboration" data-secondary="importance of"
              data-type="indexterm" id="id-KnCnSeFKfk"></a>Given the globally distributed nature of
              SRE teams, effective communication has always been a high priority in SRE. This
              chapter has discussed the tools and techniques that SRE teams use to maintain
              effective relationships among their team and with their various partner teams.
            </p>
            <p>
              Collaboration between SRE teams has its challenges, but potentially great rewards,
              including common approaches to platforms for solving problems, letting us focus on
              solving more difficult problems.
            </p>
          </section>
          <div class="footnotes" data-type="footnotes">
            <p data-type="footnote" id="id-rq7uXSATe">
              <sup><a href="communication-and-collaboration.html#id-rq7uXSATe-marker">146</a></sup>And, as we all know, culture beats
              strategy every time: <a data-type="xref" href=
              "bibliography.html#Mer11" target="_blank">[Mer11]</a>.
            </p>
            <p data-type="footnote" id="id-oAdukFqT7uz">
              <sup><a href="communication-and-collaboration.html#id-oAdukFqT7uz-marker">147</a></sup>The larger team generally tends to
              unintentionally talk over the smaller team, it's more difficult to control
              distracting side conversations, etc.
            </p>
            <p data-type="footnote" id="id-p8BuZIjFLC0">
              <sup><a href="communication-and-collaboration.html#id-p8BuZIjFLC0-marker">148</a></sup>In this particular case, the road
              to hell was indeed paved with JavaScript.
            </p>
            <p data-type="footnote" id="id-vkKuPSPhMTpC4">
              <sup><a href="communication-and-collaboration.html#id-vkKuPSPhMTpC4-marker">149</a></sup>That is, software has the same
              structure as the communications structure of the organization that produces the
              software—see <a href="https://en.wikipedia.org/wiki/Conway's_law" target=
              "_blank"><em class="hyperlink">https://en.wikipedia.org/wiki/Conway%27s_law</em></a>.
            </p>
            <p data-type="footnote" id="id-12pS9hqFpHp">
              <sup><a href="communication-and-collaboration.html#id-12pS9hqFpHp-marker">150</a></sup>DoubleClick for Publishers is a
              tool for publishers to manage ads served on their websites and in their apps.
            </p>
          </div>
        </section>
      </div>
    </div>
    <div class="footer">
      <div class="maia-aux">
        <div class="previous">
          <a href="operational-overload.html">
          <p class="footer-caption">
            previous
          </p>
          <p class="chapter-link">
            Chapter 30- Embedding an SRE to Recover from Operational Overload
          </p></a>
        </div>
        <div class="next">
          <a href="evolving-sre-engagement-model.html">
          <p class="footer-caption">
            next
          </p>
          <p class="chapter-link">
            Chapter 32- The Evolving SRE Engagement Model
          </p></a>
        </div>
        <p class="footer-link">
          Copyright © 2017 Google, Inc. Published by O'Reilly Media, Inc. Licensed under <a href=
          "https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a>
        </p>
      </div>
    </div>
    <script src="../js/main.min.js">
    </script> 
    <script src="../js/maia.js">
    </script>
  </body>
</html>
