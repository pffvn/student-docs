<!DOCTYPE html>
<html class="google" lang="en">
  <head>
    <meta charset="utf-8">
    <script>
    (function(H){H.className=H.className.replace(/\bgoogle\b/,'google-js')})(document.documentElement)
    </script>
    <meta content="initial-scale=1, minimum-scale=1, width=device-width" name="viewport">
    <title>
      Google - Site Reliability Engineering
    </title>
    <script src="../js/google.js">
    </script>
    <script>
    new gweb.analytics.AutoTrack({profile:"UA-75468017-1"});
    </script>
    <link href="../css/opensans.css" rel=
    "stylesheet">
    <link href="../css/main.min.css" rel="stylesheet">
    <link href=
    '../css/roboto.css'
    rel='stylesheet' type='text/css'>
    <link href="../../images/favicon.ico" rel="shortcut icon">
  </head>
  <body>
    <div class="menu-closed" id="curtain"></div>
    <div class="header clearfix">
      <div class="header-wrraper">
        <a class="expand" id="burger-menu"></a>
        <h2 class="chapter-title">
          Chapter 1 - Introduction
        </h2>
      </div>
    </div>
    <div class="expands" id="overlay-element">
      <div class="logo">
        <a href="https://www.google.com"><img alt="Google" src=
        "../../images/googlelogo-grey-color.png"></a>
      </div>
      <ol class="dropdown-content hide" id="drop-down">
        <li>
          <a class="menu-buttons" href="../index.html">Table of Contents</a>
        </li>
        <li>
          <a class="menu-buttons" href="foreword.html">Foreword</a>
        </li>
        <li>
          <a class="menu-buttons" href="preface.html">Preface</a>
        </li>
        <li>
          <a class="menu-buttons" href="part1.html">Part I - Introduction</a>
        </li>
        <li class='active'>
          <a class="menu-buttons" href="introduction.html">1. Introduction</a>
        </li>
        <li>
          <a class="menu-buttons" href="production-environment.html">2. The
          Production Environment at Google, from the Viewpoint of an SRE</a>
        </li>
        <li>
          <a class="menu-buttons" href="part2.html">Part II - Principles</a>
        </li>
        <li>
          <a class="menu-buttons" href="embracing-risk.html">3. Embracing
          Risk</a>
        </li>
        <li>
          <a class="menu-buttons" href="service-level-objectives.html">4.
          Service Level Objectives</a>
        </li>
        <li>
          <a class="menu-buttons" href="eliminating-toil.html">5. Eliminating
          Toil</a>
        </li>
        <li>
          <a class="menu-buttons" href="monitoring-distributed-systems.html">6.
          Monitoring Distributed Systems</a>
        </li>
        <li>
          <a class="menu-buttons" href="automation-at-google.html">7. The
          Evolution of Automation at Google</a>
        </li>
        <li>
          <a class="menu-buttons" href="release-engineering.html">8. Release
          Engineering</a>
        </li>
        <li>
          <a class="menu-buttons" href="simplicity.html">9. Simplicity</a>
        </li>
        <li>
          <a class="menu-buttons" href="part3.html">Part III - Practices</a>
        </li>
        <li>
          <a class="menu-buttons" href="practical-alerting.html">10. Practical
          Alerting</a>
        </li>
        <li>
          <a class="menu-buttons" href="being-on-call.html">11. Being
          On-Call</a>
        </li>
        <li>
          <a class="menu-buttons" href="effective-troubleshooting.html">12.
          Effective Troubleshooting</a>
        </li>
        <li>
          <a class="menu-buttons" href="emergency-response.html">13. Emergency
          Response</a>
        </li>
        <li>
          <a class="menu-buttons" href="managing-incidents.html">14. Managing
          Incidents</a>
        </li>
        <li>
          <a class="menu-buttons" href="postmortem-culture.html">15. Postmortem
          Culture: Learning from Failure</a>
        </li>
        <li>
          <a class="menu-buttons" href="tracking-outages.html">16. Tracking
          Outages</a>
        </li>
        <li>
          <a class="menu-buttons" href="testing-reliability.html">17. Testing
          for Reliability</a>
        </li>
        <li>
          <a class="menu-buttons" href="software-engineering-in-sre.html">18.
          Software Engineering in SRE</a>
        </li>
        <li>
          <a class="menu-buttons" href="load-balancing-frontend.html">19. Load
          Balancing at the Frontend</a>
        </li>
        <li>
          <a class="menu-buttons" href="load-balancing-datacenter.html">20. Load
          Balancing in the Datacenter</a>
        </li>
        <li>
          <a class="menu-buttons" href="handling-overload.html">21. Handling
          Overload</a>
        </li>
        <li>
          <a class="menu-buttons" href="addressing-cascading-failures.html">22.
          Addressing Cascading Failures</a>
        </li>
        <li>
          <a class="menu-buttons" href="managing-critical-state.html">23.
          Managing Critical State: Distributed Consensus for Reliability</a>
        </li>
        <li>
          <a class="menu-buttons" href=
          "distributed-periodic-scheduling.html">24. Distributed Periodic
          Scheduling with Cron</a>
        </li>
        <li>
          <a class="menu-buttons" href="data-processing-pipelines.html">25. Data
          Processing Pipelines</a>
        </li>
        <li>
          <a class="menu-buttons" href="data-integrity.html">26. Data Integrity:
          What You Read Is What You Wrote</a>
        </li>
        <li>
          <a class="menu-buttons" href="reliable-product-launches.html">27.
          Reliable Product Launches at Scale</a>
        </li>
        <li>
          <a class="menu-buttons" href="part4.html">Part IV - Management</a>
        </li>
        <li>
          <a class="menu-buttons" href="accelerating-sre-on-call.html">28.
          Accelerating SREs to On-Call and Beyond</a>
        </li>
        <li>
          <a class="menu-buttons" href="dealing-with-interrupts.html">29.
          Dealing with Interrupts</a>
        </li>
        <li>
          <a class="menu-buttons" href="operational-overload.html">30. Embedding
          an SRE to Recover from Operational Overload</a>
        </li>
        <li>
          <a class="menu-buttons" href=
          "communication-and-collaboration.html">31. Communication and
          Collaboration in SRE</a>
        </li>
        <li>
          <a class="menu-buttons" href="evolving-sre-engagement-model.html">32.
          The Evolving SRE Engagement Model</a>
        </li>
        <li>
          <a class="menu-buttons" href="part5.html">Part V - Conclusions</a>
        </li>
        <li>
          <a class="menu-buttons" href="lessons-learned.html">33. Lessons
          Learned from Other Industries</a>
        </li>
        <li>
          <a class="menu-buttons" href="conclusion.html">34. Conclusion</a>
        </li>
        <li>
          <a class="menu-buttons" href="availability-table.html">Appendix A.
          Availability Table</a>
        </li>
        <li>
          <a class="menu-buttons" href="service-best-practices.html">Appendix B.
          A Collection of Best Practices for Production Services</a>
        </li>
        <li>
          <a class="menu-buttons" href="incident-document.html">Appendix C.
          Example Incident State Document</a>
        </li>
        <li>
          <a class="menu-buttons" href="postmortem.html">Appendix D. Example
          Postmortem</a>
        </li>
        <li>
          <a class="menu-buttons" href="launch-checklist.html">Appendix E.
          Launch Coordination Checklist</a>
        </li>
        <li>
          <a class="menu-buttons" href="bibliography.html">Appendix F.
          Bibliography</a>
        </li>
      </ol>
    </div>
    <div id="maia-main" role="main">
      <div class="maia-teleport" id="content"></div>
      <div class="content">
        <section data-type="chapter" id="chapter_btreynor-intro">
          <h1 class="heading">
            Introduction
          </h1>
          <p class="byline author">
            Written by Benjamin Treynor Sloss<sup><a data-type="noteref" href="introduction.html#id-2opuzSjFr" id=
            "id-2opuzSjFr-marker">6</a></sup><br>
            Edited by Betsy Beyer
          </p>
          <blockquote data-type="epigraph">
            <p class="quote">
              Hope is not a strategy."
            </p>
            <p class="quote-author" data-type="attribution">
              Traditional SRE saying
            </p>
          </blockquote>
          <p>
            It is a truth universally acknowledged that systems do not run themselves. How, then,
            <em>should</em> a system—particularly a complex computing system that operates at a
            large scale—be run?
          </p>
          <section data-type="sect1" id="the-sysadmin-approach-to-service-management-xqszTN">
            <h1 class="heading">
              The Sysadmin Approach to Service Management
            </h1>
            <p>
              <a data-primary="Site Reliability Engineering (SRE)" data-secondary=
              "sysadmin approach to management" data-type="indexterm" id=
              "id-LnC7SGFYTB"></a><a data-primary="service management" data-secondary=
              "sysadmin approach to" data-type="indexterm" id="id-AnCDFZFATW"></a>Historically,
              companies have employed systems administrators to run complex computing systems.
            </p>
            <p>
              <a data-primary="systems administrators (sysadmins)" data-type="indexterm" id=
              "id-AnCPS1IATW"></a><a data-primary="sysadmins (systems administrators)" data-type=
              "indexterm" id="id-W7CoFGIbTZ"></a>This systems administrator, or sysadmin, approach
              involves assembling existing software components and deploying them to work together
              to produce a service. <span class="keep-together">Sysadmins</span> are then tasked
              with running the service and responding to events and updates as they occur. As the
              system grows in complexity and traffic volume, generating a corresponding increase in
              events and updates, the sysadmin team grows to absorb the additional work. Because
              the sysadmin role requires a markedly different skill set than that required of a
              product’s developers, developers and sysadmins are divided into discrete teams:
              "development" and "operations" or "ops."
            </p>
            <p>
              The sysadmin model of service management has several advantages. For companies
              deciding how to run and staff a service, this approach is relatively easy to
              implement: as a familiar industry paradigm, there are many examples from which to
              learn and emulate. A relevant talent pool is already widely available. An array of
              existing tools, software components (off the shelf or otherwise), and integration
              companies are available to help run those assembled systems, so a novice sysadmin
              team doesn’t have to <span class="keep-together">reinvent</span> the wheel and design
              a system from scratch.
            </p>
            <p>
              <a data-primary="costs" data-secondary="of sysadmin management approach" data-type=
              "indexterm" id="id-e4CzS2hoTW"></a><a data-primary="development/ops split" data-type=
              "indexterm" id="id-GnCZFnhpTk"></a>The sysadmin approach and the accompanying
              development/ops split has a number of disadvantages and pitfalls. These fall broadly
              into two categories: direct costs and indirect costs.
            </p>
            <p>
              <a data-primary="costs" data-secondary="direct" data-type="indexterm" id=
              "id-GnCJSQTpTk"></a>Direct costs are neither subtle nor ambiguous. Running a service
              with a team that relies on manual intervention for both change management and event
              handling becomes expensive as the service and/or traffic to the service grows,
              because the size of the team necessarily scales with the load generated by the
              system.
            </p>
            <p>
              <a data-primary="costs" data-secondary="indirect" data-type="indexterm" id=
              "id-DnC1SPcGTn"></a>The indirect costs of the development/ops split can be subtle,
              but are often more expensive to the organization than the direct costs. These costs
              arise from the fact that the two teams are quite different in background, skill set,
              and incentives. They use different vocabulary to describe situations; they carry
              different assumptions about both risk and possibilities for technical solutions; they
              have different assumptions about the target level of product stability. The split
              between the groups can easily become one of not just incentives, but also
              communication, goals, and eventually, trust and respect. This outcome is a pathology.
            </p>
            <p>
              Traditional operations teams and their counterparts in product development thus often
              end up in conflict, most visibly over how quickly software can be released to
              production. At their core, the development teams want to launch new features and see
              them adopted by users. At <em>their</em> core, the ops teams want to make sure the
              service doesn’t break while they are holding the pager. Because most outages are
              caused by some kind of change—a new configuration, a new feature launch, or a new
              type of user traffic—the two teams’ goals are fundamentally in tension.
            </p>
            <p>
              Both groups understand that it is unacceptable to state their interests in the
              baldest possible terms ("We want to launch anything, any time, without hindrance"
              versus "We won’t want to ever change anything in the system once it works"). And
              because their vocabulary and risk assumptions differ, both groups often resort to a
              familiar form of trench warfare to advance their interests. The ops team attempts to
              safeguard the running system against the risk of change by introducing launch and
              change gates. For example, launch reviews may contain an explicit check for
              <em>every</em> problem that has <em>ever</em> caused an outage in the past—that could
              be an arbitrarily long list, with not all elements providing equal value. The dev
              team quickly learns how to respond. They have fewer "launches" and more "flag flips,"
              "incremental updates," or "cherrypicks." They adopt tactics such as sharding the
              product so that fewer features are subject to the launch review.
            </p>
          </section>
          <section data-type="sect1" id=
          "googles-approach-to-service-management-site-reliability-engineering-Pasncl">
            <h1 class="heading">
              Google’s Approach to Service Management: <span class="keep-together">Site Reliability
              Engineering</span>
            </h1>
            <p>
              <a data-primary="Site Reliability Engineering (SRE)" data-secondary=
              "Google’s approach to management" data-type="indexterm" id=
              "SREgoogle1"></a><a data-primary="service management" data-secondary=
              "Google’s approach to" data-type="indexterm" id="SMgoogle1"></a>Conflict isn’t an
              inevitable part of offering a software service. Google has chosen to run our systems
              with a different approach: our Site Reliability Engineering teams focus on hiring
              software engineers to run our products and to create systems to accomplish the work
              that would otherwise be performed, often manually, by <span class=
              "keep-together">sysadmins</span>.
            </p>
            <p>
              <a data-primary="Site Reliability Engineering (SRE)" data-secondary="defined"
              data-type="indexterm" id="id-W7CESGIOcZ"></a>What exactly is Site Reliability
              Engineering, as it has come to be defined at Google? My explanation is simple: SRE is
              what happens when you ask a software engineer to design an operations team. When I
              joined Google in 2003 and was tasked with running a "Production Team" of seven
              engineers, my entire life up to that point had been software engineering. So I
              designed and managed the group the way <em>I</em> would want it to work if I worked
              as an SRE myself. That group has since matured to become Google’s present-day SRE
              team, which remains true to its origins as envisioned by a lifelong software
              engineer.
            </p>
            <p>
              <a data-primary="Site Reliability Engineering (SRE)" data-secondary=
              "team composition and skills" data-type="indexterm" id=
              "id-e4CzSjtLcW"></a><a data-primary="team building" data-secondary="team composition"
              data-type="indexterm" id="id-GnCZFWtgck"></a><a data-primary=
              "Site Reliability Engineering (SRE)" data-secondary="hiring" data-type="indexterm"
              id="id-DnCXImtocn"></a>A primary building block of Google’s approach to service
              management is the composition of each SRE team. As a whole, SREs can be broken down
              into two main categories.
            </p>
            <p>
              50–60% are Google Software Engineers, or more precisely, people who have been hired
              via the standard procedure for Google Software Engineers. The other 40–50% are
              candidates who were very close to the Google Software Engineering qualifications
              (i.e., 85–99% of the skill set required), and who <em>in addition</em> had a set of
              technical skills that isuseful to SRE but is rare for most software engineers.
              <a data-primary="team building" data-secondary="skills needed" data-type="indexterm"
              id="id-DnCaFohocn"></a>By far, UNIX system internals and networking (Layer 1 to Layer
              3) expertise are the two most common types of alternate technical skills we seek.
            </p>
            <p>
              Common to all SREs is the belief in and aptitude for developing software systems to
              solve complex problems. Within SRE, we track the career progress of both groups
              closely, and have to date found no practical difference in performance between
              engineers from the two tracks. In fact, the somewhat diverse background of the SRE
              team frequently results in clever, high-quality systems that are clearly the product
              of the synthesis of several skill sets.
            </p>
            <p>
              The result of our approach to hiring for SRE is that we end up with a team of people
              who (a) will quickly become bored by performing tasks by hand, and (b) have the skill
              set necessary to write software to replace their previously manual work, even when
              the solution is complicated. SREs also end up sharing academic and intellectual
              background with the rest of the development organization. Therefore, SRE is
              fundamentally doing work that has historically been done by an operations team, but
              using engineers with software expertise, and banking on the fact that these engineers
              are inherently both predisposed to, and have the ability to, design and implement
              automation with software to replace human labor.
            </p>
            <p>
              <a data-primary="team building" data-secondary="engineering focus" data-type=
              "indexterm" id="id-4nCqSaiQcl"></a>By design, it is crucial that SRE teams are
              focused on engineering. Without constant engineering, operations load increases and
              teams will need more people just to keep pace with the workload. Eventually, a
              traditional ops-focused group scales linearly with service size: if the products
              supported by the service succeed, the operational load will grow with traffic. That
              means hiring more people to do the same tasks over and over again.
            </p>
            <p>
              To avoid this fate, the team tasked with managing a service needs to code or it will
              drown. Therefore, Google places <em>a 50% cap on the aggregate "ops" work for all
              SREs</em>—tickets, on-call, manual tasks, etc. This cap ensures that the SRE team has
              enough time in their schedule to make the service stable and operable. This cap is an
              upper bound; over time, left to their own devices, the SRE team should end up with
              very little operational load and almost entirely engage in development tasks, because
              the service basically runs and repairs itself: we want systems that are
              <em>automatic</em>, not just <em>automated</em>. In practice, scale and new features
              keep SREs on their toes.
            </p>
            <p>
              <a data-primary="team building" data-secondary="development focus" data-type=
              "indexterm" id="id-9nCjSLUmc0"></a>Google’s rule of thumb is that an SRE team must
              spend the remaining 50% of its time actually doing development. So how do we enforce
              that threshold? In the first place, we have to measure how SRE time is spent. With
              that measurement in hand, we ensure that the teams consistently spending less than
              50% of their time on development work change their practices. Often this means
              shifting some of the operations burden back to the development team, or adding staff
              to the team without assigning that team additional operational responsibilities.
              Consciously maintaining this balance between ops and development work allows us to
              ensure that SREs have the bandwidth to engage in creative, autonomous engineering,
              while still retaining the wisdom gleaned from the operations side of running a
              service.
            </p>
            <p>
              <a data-primary="team building" data-secondary="benefits of Google's approach to"
              data-type="indexterm" id="id-ZbCxSjCpcZ"></a><a data-primary=
              "Site Reliability Engineering (SRE)" data-secondary="benefits of" data-type=
              "indexterm" id="id-zdCkFbCjc2"></a>We’ve found that Google SRE’s approach to running
              large-scale systems has many advantages. Because SREs are directly modifying code in
              their pursuit of making Google’s systems run themselves, SRE teams are characterized
              by both rapid innovation and a large acceptance of change. Such teams are relatively
              inexpensive—supporting the same service with an ops-oriented team would require a
              significantly larger number of people. Instead, the number of SREs needed to run,
              maintain, and improve a system scales sublinearly with the size of the system.
              Finally, not only does SRE circumvent the dysfunctionality of the dev/ops split, but
              this structure also improves our product development teams: easy transfers between
              product development and SRE teams cross-train the entire group, and improve skills of
              developers who otherwise may have difficulty learning how to build a million-core
              distributed system.
            </p>
            <p>
              <a data-primary="Site Reliability Engineering (SRE)" data-secondary="challenges of"
              data-type="indexterm" id="id-zdCxSNsjc2"></a>Despite these net gains, the SRE model
              is characterized by its own distinct set of challenges. One continual challenge
              Google faces is hiring SREs: not only does SRE <span class=
              "keep-together">compete</span> for the same candidates as the product development
              hiring pipeline, but the fact that we set the hiring bar so high in terms of both
              coding and system engineering skills means that our hiring pool is necessarily small.
              As our discipline is relatively new and unique, not much industry information exists
              on how to build and manage an SRE team (although hopefully this book will make
              strides in that direction!). And once an SRE team is in place, their potentially
              unorthodox approaches to service management require strong management support. For
              example, the decision to stop releases for the remainder of the quarter once an error
              budget is depleted might not be embraced by a product development team unless
              mandated by their management.<a data-primary="" data-startref="SMgoogle1" data-type=
              "indexterm" id="id-VMCQI0swcZ"></a><a data-primary="" data-startref="SREgoogle1"
              data-type="indexterm" id="id-rjCwtQszcE"></a>
            </p>
            <aside class="highlight" data-type="sidebar" id="devops-or-sre-8OS8HmcX">
              <h1 class="heading">
                DevOps or SRE?
              </h1>
              <p>
                <a data-primary="DevOps" data-type="indexterm" id="id-VMCPSrFpHOcr"></a>The term
                “DevOps” emerged in industry in late 2008 and as of this writing (early 2016) is
                still in a state of flux. Its core principles—involvement of the IT function in
                each phase of a system’s design and development, heavy reliance on automation
                versus human effort, the application of engineering practices and tools to
                operations tasks—are consistent with many of SRE’s principles and practices. One
                could view DevOps as a generalization of several core SRE principles to a wider
                range of organizations, management structures, and personnel. One could
                equivalently view SRE as a specific implementation of DevOps with some
                idiosyncratic extensions.
              </p>
            </aside>
          </section>
          <section data-type="sect1" id="tenets-of-sre-OKseie">
            <h1 class="heading">
              Tenets of SRE
            </h1>
            <p>
              <a data-primary="Site Reliability Engineering (SRE)" data-secondary="tenets of"
              data-type="indexterm" id="SREten1"></a>While the nuances of workflows, priorities,
              and day-to-day operations vary from SRE team to SRE team, all share a set of basic
              responsibilities for the service(s) they support, and adhere to the same core tenets.
              In general, an SRE team is responsible for the <em>availability, latency,
              performance, efficiency, change management, monitoring, emergency response, and
              capacity planning</em> of their service(s). We have codified rules of engagement and
              principles for how SRE teams interact with their environment—not only the production
              environment, but also the product development teams, the testing teams, the users,
              and so on. Those rules and work practices help us to maintain our focus on
              engineering work, as opposed to operations work.
            </p>
            <p>
              The following section discusses each of the core tenets of Google SRE.
            </p>
            <section data-type="sect2" id="ensuring-a-durable-focus-on-engineering-2ksLtair">
              <h2 class="subheaders">
                Ensuring a Durable Focus on Engineering
              </h2>
              <p>
                <a data-primary="team building" data-secondary="engineering focus" data-type=
                "indexterm" id="id-DnC1SWFvtzi7"></a>As already discussed, Google caps operational
                work for SREs at 50% of their time. Their remaining time should be spent using
                their coding skills on project work. In practice, this is accomplished by
                monitoring the amount of operational work being done by SREs, and redirecting
                excess operational work to the product development teams: reassigning bugs and
                tickets to development managers, [re]integrating developers into on-call pager
                rotations, and so on. The redirection ends when the operational load drops back to
                50% or lower. This also provides an effective feedback mechanism, guiding
                developers to build systems that don’t need manual intervention. This approach
                works well when the entire organization—SRE and development alike—understands why
                the safety valve mechanism exists, and supports the goal of having no overflow
                events because the product doesn’t generate enough operational load to require it.
              </p>
              <p>
                <a data-primary="on-call" data-secondary="target event volume" data-type=
                "indexterm" id="id-kVCkS2IDt7iO"></a>When they are focused on operations work, on
                average, SREs should receive a maximum of two events per 8–12-hour on-call shift.
                This target volume gives the on-call engineer enough time to handle the event
                accurately and quickly, clean up and restore normal service, and then conduct a
                postmortem. If more than two events occur regularly per on-call shift, problems
                can’t be investigated thoroughly and engineers are sufficiently overwhelmed to
                prevent them from learning from these events. A scenario of pager fatigue also
                won’t improve with scale. Conversely, if on-call SREs consistently receive fewer
                than one event per shift, keeping them on point is a waste of their time.
              </p>
              <p>
                <a data-primary="postmortems" data-secondary="guidelines for" data-type="indexterm"
                id="id-4nCqSqtNt7iN"></a>Postmortems should be written for all significant
                incidents, regardless of whether or not they paged; postmortems that did not
                trigger a page are even more valuable, as they likely point to clear monitoring
                gaps. This investigation should establish what happened in detail, find all root
                causes of the event, and assign actions to correct the problem or improve how it is
                addressed next time. Google operates under a <em>blame-free postmortem
                culture</em>, with the goal of exposing faults and applying engineering to fix
                these faults, rather than avoiding or minimizing them.
              </p>
            </section>
            <section data-type="sect2" id=
            "pursuing-maximum-change-velocity-without-violating-a-services-slo-pWsJh2iL">
              <h2 class="subheaders">
                Pursuing Maximum Change Velocity Without Violating a Service’s SLO
              </h2>
              <p>
                <a data-primary="error budgets" data-secondary="guidelines for" data-type=
                "indexterm" id="id-kVCkSpFQh7iO"></a><a data-primary="reliability testing"
                data-secondary="error budgets" data-type="indexterm" id=
                "id-4nC2FYFkh7iN"></a>Product development and SRE teams can enjoy a productive
                working relationship by eliminating the structural conflict in their respective
                goals. The structural conflict is between pace of innovation and product stability,
                and as described earlier, this conflict often is expressed indirectly. In SRE we
                bring this conflict to the fore, and then resolve it with the introduction of an
                <em>error budget</em>.
              </p>
              <p>
                The error budget stems from the observation that <em>100% is the wrong reliability
                target for basically everything</em> (pacemakers and anti-lock brakes being notable
                exceptions). In general, for any software service or system, 100% is not the right
                reliability target because no user can tell the difference between a system being
                100% available and 99.999% available. There are many other systems in the path
                between user and service (their laptop, their home WiFi, their ISP, the power
                grid…) and those systems collectively are far less than 99.999% available. Thus,
                the marginal difference between 99.999% and 100% gets lost in the noise of other
                unavailability, and the user receives no benefit from the enormous effort required
                to add that last 0.001% of availability.
              </p>
              <p>
                If 100% is the wrong reliability target for a system, what, then, is the right
                reliability target for the system? This actually isn’t a technical question at
                all—it’s a product question, which should take the following considerations into
                account:
              </p>
              <ul>
                <li>What level of availability will the users be happy with, given how they use the
                product?
                </li>
                <li>What alternatives are available to users who are dissatisfied with the
                product’s availability?
                </li>
                <li>What happens to users’ usage of the product at different availability levels?
                </li>
              </ul>
              <p>
                The business or the product must establish the system’s availabilit target. Once
                that target is established, the error budget is one minus the availability target.
                A service that’s 99.99% available is 0.01% unavailable. That permitted 0.01%
                unavailability is the service’s <em>error budget</em>. We can spend the budget on
                anything we want, as long as we don’t overspend it.
              </p>
              <p>
                So how do we want to spend the error budget? The development team wants to launch
                features and attract new users. Ideally, we would spend all of our error budget
                taking risks with things we launch in order to launch them quickly. This basic
                premise describes the whole model of error budgets. As soon as SRE activities are
                conceptualized in this framework, freeing up the error budget through tactics such
                as phased rollouts and 1% experiments can optimize for quicker launches.
              </p>
              <p>
                The use of an error budget resolves the structural conflict of incentives between
                development and SRE. SRE’s goal is no longer "zero outages"; rather, SREs and
                product developers aim to spend the error budget getting maximum feature velocity.
                This change makes all the difference. An outage is no longer a "bad" thing—it is an
                expected part of the process of innovation, and an occurrence that bothdevelopment
                and SRE teams manage rather than fear.
              </p>
            </section>
            <section data-type="sect2" id="monitoring-o8sQTGi1">
              <h2 class="subheaders">
                Monitoring
              </h2>
              <p>
                <a data-primary="monitoring distributed systems" data-secondary="guidelines for"
                data-type="indexterm" id="id-4nCqSYFGT7iN"></a>Monitoring is one of the primary
                means by which service owners keep track of a system’s health and availability. As
                such, monitoringstrategy should be constructed thoughtfully. A classic and
                commonapproach to monitoring is to watch for a specific value or condition,and then
                to trigger an email alert when that value is exceeded or that condition occurs.
                However, this type of email alerting is not aneffective solution: a system that
                requires a human to read an emailand decide whether or not some type of action
                needs to be taken inresponse is fundamentally flawed. Monitoring should never
                require ahuman to interpret any part of the alerting domain. Instead,
                softwareshould do the interpreting, and humans should be notified only whenthey
                need to take action.
              </p>
              <p class="pagebreak-before">
                <a data-primary="monitoring distributed systems" data-secondary=
                "valid monitoring outputs" data-seealso="Borgmon; time-series monitoring"
                data-type="indexterm" id="id-JnCDSjI2TAiN"></a>There are three kinds of valid
                monitoring output:
              </p>
              <dl>
                <dt class="subheaders">
                  Alerts
                </dt>
                <dd>
                  <p>
                    Signify that a human needs to take action immediately in response to something
                    that is either happening or about to happen, in order to improve the situation.
                  </p>
                </dd>
                <dt class="subheaders">
                  Tickets
                </dt>
                <dd>
                  <p>
                    Signify that a human needs to take action, but not immediately. The system
                    cannot automatically handle the situation, but if a human takes action in a few
                    days, no damage will result.
                  </p>
                </dd>
                <dt class="subheaders">
                  Logging
                </dt>
                <dd>
                  <p>
                    No one needs to look at this information, but it is recorded for diagnostic or
                    forensic purposes. The expectation is that no one reads logs unless something
                    else prompts them to do so.
                  </p>
                </dd>
              </dl>
            </section>
            <section data-type="sect2" id="emergency-response-g0sKcpiL">
              <h2 class="subheaders">
                Emergency Response
              </h2>
              <p>
                <a data-primary="emergency response" data-secondary="guidelines for" data-type=
                "indexterm" id="id-JnCDSlFVcAiN"></a><a data-primary="mean time" data-secondary=
                "to failure (MTTF)" data-type="indexterm" id="id-9nCdFvFmc4ip"></a><a data-primary=
                "mean time" data-secondary="to repair (MTTR)" data-type="indexterm" id=
                "id-ZbCnIMFpcziJ"></a>Reliability is a function of mean time to failure (MTTF) and
                mean time to repair (MTTR) <a data-type="xref" href=
                "bibliography.html#Sch15" target="_blank">[Sch15]</a>. The most
                relevant metric in evaluating the effectiveness of emergency response is how
                quickly the response team can bring the system back to health—that is, the MTTR.
              </p>
              <p>
                Humans add latency. Even if a given system experiences more <em>actual</em>
                failures, a system that can avoid emergencies that require human intervention will
                have higher availability than a system that requires hands-on intervention. When
                humans are necessary, we have found that thinking through and recording the best
                practices ahead of time in a "playbook" produces roughly a 3x improvement in MTTR
                as compared to the strategy of "winging it." The hero jack-of-all-trades on-call
                engineer does work, but the practiced on-call engineer armed with a playbook works
                much better. While no playbook, no matter how comprehensive it may be, is a
                substitute for smart engineers able to think on the fly, clear and thorough
                troubleshooting steps and tips are valuable when responding to a high-stakes or
                time-sensitive page. Thus, Google SRE relies on on-call playbooks, in addition to
                exercises such as the "Wheel of Misfortune,"<sup><a data-type="noteref" href=
                "introduction.html#id-MJbubFnIjcqiN" id="id-MJbubFnIjcqiN-marker">7</a></sup> to prepare engineers
                to react to on-call events.
              </p>
            </section>
            <section data-type="sect2" id="change-management-q8sdiQiA">
              <h2 class="subheaders">
                Change Management
              </h2>
              <p>
                <a data-primary="automation" data-secondary="best practices for change management"
                data-type="indexterm" id="id-9nCjSvFPi4ip"></a><a data-primary="best practices"
                data-secondary="for change management" data-secondary-sortas="change management"
                data-type="indexterm" id="id-ZbC1FMFqiziJ"></a><a data-primary="change management"
                data-seealso="automation" data-type="indexterm" id="id-zdCXIGFeiGij"></a>SRE has
                found that roughly 70% of outages are due to changes in a live system. Best
                practices in this domain use automation to accomplish the following:
              </p>
              <ul class="pagebreak-before">
                <li>Implementing progressive rollouts
                </li>
                <li>Quickly and accurately detecting problems
                </li>
                <li>Rolling back changes safely when problems arise
                </li>
              </ul>
              <p>
                This trio of practices effectively minimizes the aggregate number of users and
                operations exposed to bad changes. By removing humans from the loop, these
                practices avoid the normal problems of fatigue, familiarity/contempt, and
                inattention to highly repetitive tasks. As a result, both release velocity and
                safety increase.
              </p>
            </section>
            <section data-type="sect2" id="demand-forecasting-and-capacity-planning-1LseuQiN">
              <h2 class="subheaders">
                Demand Forecasting and Capacity Planning
              </h2>
              <p>
                <a data-primary="demand forecasting" data-type="indexterm" id=
                "id-ZbCxSMFEuziJ"></a><a data-primary="capacity planning" data-secondary=
                "mandatory steps for" data-type="indexterm" id="id-zdCkFGFvuGij"></a>Demand
                forecasting and capacity planning can be viewed as ensuring that there is
                sufficient capacity and redundancy to serve projected future demand with the
                required availability. There’s nothing particularly special about these concepts,
                except that a surprising number of services and teams don’t take the steps
                necessary to ensure that the required capacity is in place by the time it is
                needed. Capacity planning should take both organic growth (which stems from natural
                product adoption and usage by customers) and inorganic growth (which results from
                events like feature launches, marketing campaigns, or other business-driven
                changes) into account.
              </p>
              <p>
                Several steps are mandatory in capacity planning:
              </p>
              <ul>
                <li>An accurate organic demand forecast, which extends beyond the lead time
                required for acquiring capacity
                </li>
                <li>An accurate incorporation of inorganic demand sources into the demand
                <span class="keep-together">forecast</span>
                </li>
                <li>Regular load testing of the system to correlate raw capacity(servers, disks,
                and so on) to service capacity
                </li>
              </ul>
              <p>
                Because capacity is critical to availability, it naturally follows that the SRE
                team must be in charge of capacity planning, which means they also must be in
                charge of provisioning.
              </p>
            </section>
            <section data-type="sect2" id="provisioning-YmsyU7iA">
              <h2 class="subheaders">
                Provisioning
              </h2>
              <p>
                <a data-primary="provisioning, guidelines for" data-type="indexterm" id=
                "id-zdCxSGFlUGij"></a>Provisioning combines both change management and capacity
                planning. In our experience, provisioning must be conducted quickly and only when
                necessary, as capacity is expensive. This exercise must also be done correctly or
                capacity doesn’t work when needed. Adding new capacity often involves spinning up a
                new instance or location, making significant modification to existing systems
                (configuration files, load balancers, networking), and validating that the new
                capacity performs and delivers correct results. Thus, it is a riskier operation
                than load shifting, which is often done multiple times per hour, and must be
                treated with a corresponding degree of extra caution.
              </p>
            </section>
            <section data-type="sect2" id="efficiency-and-performance-vJsbCDiW">
              <h2 class="subheaders">
                Efficiency and Performance
              </h2>
              <p>
                <a data-primary="performance" data-secondary="efficiency and" data-type="indexterm"
                id="id-yYCASpFdCOi1"></a>Efficient use of resources is important any time a service
                cares about money. Because SRE ultimately controls provisioning, it must also be
                involved in any work on utilization, as utilization is a function of how a given
                service works and how it is provisioned. It follows that paying close attention to
                the provisioning strategy for a service, and therefore its utilization, provides a
                very, very big lever on the service’s total costs.
              </p>
              <p>
                Resource use is a function of demand (load), capacity, and software efficiency.
                SREs predict demand, provision capacity, and can modify the software. These three
                factors are a large part (though not the entirety) of a service’s efficiency.
              </p>
              <p>
                <a data-primary="" data-startref="SREten1" data-type="indexterm" id=
                "id-rjCXSNt2Cnim"></a>Software systems become slower as load is added to them. A
                slowdown in a service equates to a loss of capacity. At some point, a slowing
                system stops serving, which corresponds to infinite slowness. SREs provision to
                meet a capacity target <em>at a specific response speed</em>, and thus are keenly
                interested in a service’s performance. SREs and product developers will (and
                should) monitor and modify a service to improve its performance, thus adding
                capacity and improving efficiency.<sup><a data-type="noteref" href=
                "introduction.html#id-a82uNIKtnCgiL" id="id-a82uNIKtnCgiL-marker">8</a></sup>
              </p>
            </section>
          </section>
          <section data-type="sect1" id="the-end-of-the-beginning-XQsDud">
            <h1 class="heading">
              The End of the Beginning
            </h1>
            <p>
              <a data-primary="SRE Way" data-type="indexterm" id="id-e4CzSJFGuW"></a>Site
              Reliability Engineering represents a significant break from existing industry best
              practices for managing large, complicated services. Motivated originally by
              familiarity—"as a software engineer, this is how I would want to invest my time to
              accomplish a set of repetitive tasks"—it has become much more: a set of principles, a
              set of practices, a set of incentives, and a field of endeavor within the larger
              software engineering discipline. The rest of the book explores the SRE Way in detail.
            </p>
          </section>
          <div class="footnotes" data-type="footnotes">
            <p data-type="footnote" id="id-2opuzSjFr">
              <sup><a href="introduction.html#id-2opuzSjFr-marker">6</a></sup>Vice President, Google Engineering,
              founder of Google SRE
            </p>
            <p data-type="footnote" id="id-MJbubFnIjcqiN">
              <sup><a href="introduction.html#id-MJbubFnIjcqiN-marker">7</a></sup>See <a data-type="xref" href=
              "accelerating-sre-on-call.html#xref_training_disaster-rpg">Disaster
              Role Playing</a>.
            </p>
            <p data-type="footnote" id="id-a82uNIKtnCgiL">
              <sup><a href="introduction.html#id-a82uNIKtnCgiL-marker">8</a></sup>For further discussion of how this
              collaboration can work in practice, see <a data-type="xref" href=
              "operational-overload.html#xref_comms-collab_production-meetings">Communications:
              Production Meetings</a>.
            </p>
          </div>
        </section>
      </div>
    </div>
    <div class="footer">
      <div class="maia-aux">
        <div class="previous">
          <a href="part1.html">
          <p class="footer-caption">
            previous
          </p>
          <p class="chapter-link">
            Part I - Introduction
          </p></a>
        </div>
        <div class="next">
          <a href="production-environment.html">
          <p class="footer-caption">
            next
          </p>
          <p class="chapter-link">
            Chapter 2- The Production Environment at Google, from the Viewpoint of an SRE
          </p></a>
        </div>
        <p class="footer-link">
          Copyright © 2017 Google, Inc. Published by O'Reilly Media, Inc. Licensed under <a href=
          "https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a>
        </p>
      </div>
    </div>
    <script src="../js/main.min.js">
    </script> 
    <script src="../js/maia.js">
    </script>
  </body>
</html>
